{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "Path().resolve()\n",
    "sys.path.append(os.path.join(Path().resolve(), '..'))\n",
    "import numpy as np\n",
    "from datasets import ptb\n",
    "import dezero.layers as L\n",
    "import dezero.functions as F\n",
    "from dezero.optimizers import Adam\n",
    "from dezero import Variable, Model\n",
    "from dezero import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from data import PTB\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2bf5db3e89490abb32a8f44c9a286c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1285416ef240699e5612541c783119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9295.79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_eopch = 1\n",
    "eps = 1e-8\n",
    "\n",
    "trainset = PTB(window_size=window_size)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "corpus = trainset.corpus\n",
    "vocab_size = len(trainset.word_to_id)\n",
    "\n",
    "\n",
    "class CBOW(Model):\n",
    "    def __init__(self, vocab_size, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.embed_in = L.EmbedID(vocab_size, hidden_dim)\n",
    "        self.embed_out = L.EmbedID(vocab_size, hidden_dim)\n",
    "        self.sampler = UnigramSampler(corpus)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed_in(x).sum(axis=1)\n",
    "\n",
    "    def embed(self, y):\n",
    "        return self.embed_out(y)\n",
    "\n",
    "\n",
    "model = CBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam().setup(model)\n",
    "sampler = UnigramSampler(corpus)\n",
    "\n",
    "info = {}\n",
    "info['train_loss'] = []\n",
    "for epoch in tqdm(range(max_eopch)):\n",
    "    for x, y in tqdm(trainloader, total =trainloader.data_size/trainloader.batch_size, leave = False):\n",
    "        loss = 0\n",
    "\n",
    "        # positive example\n",
    "        pred = model(x)\n",
    "        embed = model.embed(y)\n",
    "        prob = F.sigmoid((pred * embed).sum(axis=1))\n",
    "        loss -= F.log(prob + eps).sum()\n",
    "\n",
    "        # negative example\n",
    "        neg_y = sampler.get_negative_sample(y)\n",
    "        neg_embed = model.embed(neg_y).transpose(1, 0, 2)\n",
    "        for i in range(len(neg_embed)):\n",
    "            prob = F.sigmoid((pred * neg_embed[i]).sum(axis=1))\n",
    "            loss -= F.log(1 - prob + eps).sum()\n",
    "\n",
    "        # update parameters\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        info['train_loss'] += [loss.data]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
